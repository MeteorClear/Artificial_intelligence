{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed_all(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`퍼셉트론(Perceptron)`은 프랑크 로젠블라트(Frank Rosenblatt)가 1957년에 제안한 `초기 형태의 인공 신경망`\n",
    "\n",
    "다수의 입력으로부터 하나의 결과를 내보내는 알고리즘\n",
    "\n",
    "각 입력값과 그에 해당되는 가중치의 곱의 전체 합이 `임계치(threshold)`를 넘으면 `활성화 함수(Activation Function)`(여기에선 `계단 함수, Step function`)에 의해 특정 값을 출력함\n",
    "\n",
    "$ if \\displaystyle\\sum_{i}^{n} W_ix_i + b \\geq \\theta \\rightarrow y = 1 $\n",
    "\n",
    "$ if \\displaystyle\\sum_{i}^{n} W_ix_i + b < \\theta \\rightarrow y = 0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`활성화 함수(Activation Function)`는 출력을 변형시키는 함수\n",
    "\n",
    "계단 함수를 시그모이드 함수로 변경시 구조적으로 로지스틱 회귀와 같음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단층 퍼셉트론(Single-Layer Perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "퍼셉트론은 구조에 따라 `단층 퍼셉트론(Single-Layer Perceptron)`, `다층 퍼셉트론(Multi Layer Perceptron)` 으로 구분된다\n",
    "\n",
    "단층 퍼셉트론은 값을 보내는 단계과 값을 받아서 출력하는 두 단계로 이루어 지며, 각 단계를 `층(layer)`이라 한다.\n",
    "\n",
    "따라서 각 층을 `입력층(input layer)`, `출력층(output layer)` 이라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단층 퍼셉트론으로 구현 가능한 예시로 AND, NAND, OR 게이트가 있다.\n",
    "\n",
    "이 경우 입력은 2개 출력은 1개 이며, 따라서 가중치도 2개이다.\n",
    "\n",
    "가중치 편향 조합을 계산해서 넣으면 작동함을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gate:\n",
    "    def __init__(self, w1, w2, b):\n",
    "        self.w1 = w1\n",
    "        self.w2 = w2\n",
    "        self.b = b\n",
    "\n",
    "    def step(self, input_value):\n",
    "        return int(input_value >= 0)\n",
    "\n",
    "    def gate(self, x1, x2):\n",
    "        return self.step(x1*self.w1 + x2*self.w2 + self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 1\n"
     ]
    }
   ],
   "source": [
    "# AND\n",
    "AND_gate = gate(0.5, 0.5, -0.7)\n",
    "print(AND_gate.gate(0,0), AND_gate.gate(0,1), AND_gate.gate(1,0), AND_gate.gate(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1 0\n"
     ]
    }
   ],
   "source": [
    "# NAND\n",
    "NAND_gate = gate(-0.5, -0.5, 0.7)\n",
    "print(NAND_gate.gate(0,0), NAND_gate.gate(0,1), NAND_gate.gate(1,0), NAND_gate.gate(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 1 1\n"
     ]
    }
   ],
   "source": [
    "# OR\n",
    "OR_gate = gate(0.6, 0.6, -0.5)\n",
    "print(OR_gate.gate(0,0), OR_gate.gate(0,1), OR_gate.gate(1,0), OR_gate.gate(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XOR 게이트는 단층 퍼셉트론으로 구현이 불가능하다.\n",
    "\n",
    "수학적 구조상 단층 퍼셉트론은 두 영역을 구분하는 직선을 찾는것인데, XOR 게이트의 값은 하나의 직선으로 두 영역을 분리 할 수 없기 때문이다.\n",
    "\n",
    "이는 선형 영역으로 분리해서 발생하는 문제로 비선형 영역으로 분리하면 구현 가능하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR 입출력\n",
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to('cuda')\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 활성화 함수로 시그모이드 사용\n",
    "linear = nn.Linear(2, 1, bias=True)\n",
    "sigmoid = nn.Sigmoid()\n",
    "model = nn.Sequential(linear, sigmoid).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0, 1 을 분류하는 이진 분류 문제이므로 이진크로스엔트로피 함수 사용\n",
    "# 비용 함수와 옵티마이저 정의\n",
    "criterion = torch.nn.BCELoss().to('cuda')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7018222212791443\n",
      "100 0.6931473016738892\n",
      "200 0.6931471824645996\n",
      "300 0.6931471824645996\n",
      "400 0.6931471824645996\n",
      "500 0.6931471824645996\n",
      "600 0.6931471824645996\n",
      "700 0.6931471824645996\n",
      "800 0.6931471824645996\n",
      "900 0.6931471824645996\n",
      "1000 0.6931471824645996\n",
      "1100 0.6931471824645996\n",
      "1200 0.6931471824645996\n",
      "1300 0.6931471824645996\n",
      "1400 0.6931471824645996\n",
      "1500 0.6931471824645996\n",
      "1600 0.6931471824645996\n",
      "1700 0.6931471824645996\n",
      "1800 0.6931471824645996\n",
      "1900 0.6931471824645996\n",
      "2000 0.6931471824645996\n",
      "2100 0.6931471824645996\n",
      "2200 0.6931471824645996\n",
      "2300 0.6931471824645996\n",
      "2400 0.6931471824645996\n",
      "2500 0.6931471824645996\n",
      "2600 0.6931471824645996\n",
      "2700 0.6931471824645996\n",
      "2800 0.6931471824645996\n",
      "2900 0.6931471824645996\n",
      "3000 0.6931471824645996\n",
      "3100 0.6931471824645996\n",
      "3200 0.6931471824645996\n",
      "3300 0.6931471824645996\n",
      "3400 0.6931471824645996\n",
      "3500 0.6931471824645996\n",
      "3600 0.6931471824645996\n",
      "3700 0.6931471824645996\n",
      "3800 0.6931471824645996\n",
      "3900 0.6931471824645996\n",
      "4000 0.6931471824645996\n",
      "4100 0.6931471824645996\n",
      "4200 0.6931471824645996\n",
      "4300 0.6931471824645996\n",
      "4400 0.6931471824645996\n",
      "4500 0.6931471824645996\n",
      "4600 0.6931471824645996\n",
      "4700 0.6931471824645996\n",
      "4800 0.6931471824645996\n",
      "4900 0.6931471824645996\n",
      "5000 0.6931471824645996\n",
      "5100 0.6931471824645996\n",
      "5200 0.6931471824645996\n",
      "5300 0.6931471824645996\n",
      "5400 0.6931471824645996\n",
      "5500 0.6931471824645996\n",
      "5600 0.6931471824645996\n",
      "5700 0.6931471824645996\n",
      "5800 0.6931471824645996\n",
      "5900 0.6931471824645996\n",
      "6000 0.6931471824645996\n",
      "6100 0.6931471824645996\n",
      "6200 0.6931471824645996\n",
      "6300 0.6931471824645996\n",
      "6400 0.6931471824645996\n",
      "6500 0.6931471824645996\n",
      "6600 0.6931471824645996\n",
      "6700 0.6931471824645996\n",
      "6800 0.6931471824645996\n",
      "6900 0.6931471824645996\n",
      "7000 0.6931471824645996\n",
      "7100 0.6931471824645996\n",
      "7200 0.6931471824645996\n",
      "7300 0.6931471824645996\n",
      "7400 0.6931471824645996\n",
      "7500 0.6931471824645996\n",
      "7600 0.6931471824645996\n",
      "7700 0.6931471824645996\n",
      "7800 0.6931471824645996\n",
      "7900 0.6931471824645996\n",
      "8000 0.6931471824645996\n",
      "8100 0.6931471824645996\n",
      "8200 0.6931471824645996\n",
      "8300 0.6931471824645996\n",
      "8400 0.6931471824645996\n",
      "8500 0.6931471824645996\n",
      "8600 0.6931471824645996\n",
      "8700 0.6931471824645996\n",
      "8800 0.6931471824645996\n",
      "8900 0.6931471824645996\n",
      "9000 0.6931471824645996\n",
      "9100 0.6931471824645996\n",
      "9200 0.6931471824645996\n",
      "9300 0.6931471824645996\n",
      "9400 0.6931471824645996\n",
      "9500 0.6931471824645996\n",
      "9600 0.6931471824645996\n",
      "9700 0.6931471824645996\n",
      "9800 0.6931471824645996\n",
      "9900 0.6931471824645996\n",
      "10000 0.6931471824645996\n"
     ]
    }
   ],
   "source": [
    "# 비용이 줄어들지 않음을 볼 수 있음\n",
    "for step in range(10001): \n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "\n",
    "    # 비용 함수\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 100 == 0: # 100번째 에포크마다 비용 출력\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 출력값(Hypothesis): \n",
      " [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]]\n",
      "모델의 예측값(Predicted): \n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "실제값(Y): \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "정확도(Accuracy):  0.5\n"
     ]
    }
   ],
   "source": [
    "# 단층 퍼셉트론으론 XOR 문제를 풀 수 없음을 볼 수 있음\n",
    "with torch.no_grad():\n",
    "    hypothesis = model(X)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "    print('모델의 출력값(Hypothesis): \\n', hypothesis.detach().cpu().numpy())\n",
    "    print('모델의 예측값(Predicted): \\n', predicted.detach().cpu().numpy())\n",
    "    print('실제값(Y): \\n', Y.cpu().numpy())\n",
    "    print('정확도(Accuracy): ', accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다층 퍼셉트론(MultiLayer Perceptron, MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XOR 게이트를 기존의 AND, NAND, OR 게이트를 조합하면 만들 수 있듯이, 퍼셉트론도 여러 층을 쌓으면 단층의 문제를 해결 가능하다\n",
    "\n",
    "단층 퍼셉트론은 입력층과 출력층만 존재하지만, 다층 퍼셉트론은 입력층과 출력층 사이에 존재하는 `은닉층(hidden layer)`이 추가된다.\n",
    "\n",
    "다층 퍼셉트론은 본래 은닉층이 1개 이상인 퍼셉트론을 뜻하지만 은닉층의 개수는 2개일 수도 있고, 수십 개일수도 있고 사용자가 설정하기 나름\n",
    "\n",
    "은닉층이 2개 이상인 신경망을 `심층 신경망(Deep Neural Network, DNN)` \n",
    "\n",
    "심층 신경망은 다층 퍼셉트론만 이야기 하는 것이 아니라, 여러 변형된 다양한 신경망들도 은닉층이 2개 이상이 되면 심층 신경망이라 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가중치를 스스로 찾아내도록 자동화시켜야하는데, 이것이 머신 러닝에서 말하는 `학습(training)` 단계에 해당\n",
    "\n",
    "손실 함수(Loss function)와 옵티마이저(Optimizer)를 사용\n",
    "\n",
    "심층 신경망을 학습시키는 경우, `딥 러닝(Deep Learning)` 이라 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR 입출력\n",
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to('cuda')\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 은닉층이 3개인 인공신경망\n",
    "model = nn.Sequential(\n",
    "        nn.Linear(2, 10, bias=True), # input_layer = 2, hidden_layer1 = 10\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(10, 10, bias=True), # hidden_layer1 = 10, hidden_layer2 = 10\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(10, 10, bias=True), # hidden_layer2 = 10, hidden_layer3 = 10\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(10, 1, bias=True), # hidden_layer3 = 10, output_layer = 1\n",
    "        nn.Sigmoid()\n",
    "        ).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이진 분류 이므로 이진크로스엔트로피 함수를 비용함수로 사용\n",
    "criterion = torch.nn.BCELoss().to('cuda')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)  # modified learning rate from 0.1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7555788159370422\n",
      "100 0.6931402683258057\n",
      "200 0.6931398510932922\n",
      "300 0.6931394934654236\n",
      "400 0.6931390762329102\n",
      "500 0.693138599395752\n",
      "600 0.6931382417678833\n",
      "700 0.6931377649307251\n",
      "800 0.6931372880935669\n",
      "900 0.6931368112564087\n",
      "1000 0.6931363344192505\n",
      "1100 0.6931357979774475\n",
      "1200 0.6931352615356445\n",
      "1300 0.6931347250938416\n",
      "1400 0.693134069442749\n",
      "1500 0.6931334733963013\n",
      "1600 0.693132758140564\n",
      "1700 0.6931321620941162\n",
      "1800 0.6931313276290894\n",
      "1900 0.693130612373352\n",
      "2000 0.6931297779083252\n",
      "2100 0.6931288242340088\n",
      "2200 0.6931278705596924\n",
      "2300 0.693126916885376\n",
      "2400 0.69312584400177\n",
      "2500 0.6931246519088745\n",
      "2600 0.693123459815979\n",
      "2700 0.693122148513794\n",
      "2800 0.6931207180023193\n",
      "2900 0.6931191682815552\n",
      "3000 0.6931175589561462\n",
      "3100 0.693115770816803\n",
      "3200 0.6931138038635254\n",
      "3300 0.6931116580963135\n",
      "3400 0.693109393119812\n",
      "3500 0.6931068301200867\n",
      "3600 0.6931039690971375\n",
      "3700 0.6931008100509644\n",
      "3800 0.6930972933769226\n",
      "3900 0.6930934190750122\n",
      "4000 0.6930890083312988\n",
      "4100 0.6930840611457825\n",
      "4200 0.6930783987045288\n",
      "4300 0.6930720806121826\n",
      "4400 0.6930645704269409\n",
      "4500 0.6930559873580933\n",
      "4600 0.693045973777771\n",
      "4700 0.6930340528488159\n",
      "4800 0.6930198669433594\n",
      "4900 0.6930025219917297\n",
      "5000 0.6929812431335449\n",
      "5100 0.6929546594619751\n",
      "5200 0.6929207444190979\n",
      "5300 0.6928764581680298\n",
      "5400 0.6928167939186096\n",
      "5500 0.692733883857727\n",
      "5600 0.6926132440567017\n",
      "5700 0.6924275159835815\n",
      "5800 0.6921188831329346\n",
      "5900 0.6915477514266968\n",
      "6000 0.6903039813041687\n",
      "6100 0.6867539882659912\n",
      "6200 0.6699955463409424\n",
      "6300 0.5371477603912354\n",
      "6400 0.044705260545015335\n",
      "6500 0.009273223578929901\n",
      "6600 0.0047081876546144485\n",
      "6700 0.0030708785634487867\n",
      "6800 0.0022507430985569954\n",
      "6900 0.0017643080791458488\n",
      "7000 0.0014445894630625844\n",
      "7100 0.001219413010403514\n",
      "7200 0.0010527980048209429\n",
      "7300 0.0009248299174942076\n",
      "7400 0.0008236134890466928\n",
      "7500 0.0007416462758556008\n",
      "7600 0.0006740061799064279\n",
      "7700 0.0006173035362735391\n",
      "7800 0.0005690875113941729\n",
      "7900 0.0005276135634630919\n",
      "8000 0.0004916042671538889\n",
      "8100 0.00046004654723219573\n",
      "8200 0.00043218943756073713\n",
      "8300 0.0004073714080732316\n",
      "8400 0.00038518806104548275\n",
      "8500 0.00036519026616588235\n",
      "8600 0.0003471492964308709\n",
      "8700 0.0003307165461592376\n",
      "8800 0.0003157338360324502\n",
      "8900 0.0003020365838892758\n",
      "9000 0.00028940275660715997\n",
      "9100 0.00027776791830547154\n",
      "9200 0.0002670063986442983\n",
      "9300 0.00025703676510602236\n",
      "9400 0.00024774495977908373\n",
      "9500 0.00023909744049888104\n",
      "9600 0.00023100276303011924\n",
      "9700 0.00022343461751006544\n",
      "9800 0.0002163100434700027\n",
      "9900 0.00020963806309737265\n",
      "10000 0.00020333979045972228\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    # forward 연산\n",
    "    hypothesis = model(X)\n",
    "\n",
    "    # 비용 함수\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100의 배수에 해당되는 에포크마다 비용을 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print(epoch, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 출력값(Hypothesis): \n",
      " [[1.9882395e-04]\n",
      " [9.9977750e-01]\n",
      " [9.9982017e-01]\n",
      " [2.1199770e-04]]\n",
      "모델의 예측값(Predicted): \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "실제값(Y): \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "정확도(Accuracy):  1.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    hypothesis = model(X)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "    print('모델의 출력값(Hypothesis): \\n', hypothesis.detach().cpu().numpy())\n",
    "    print('모델의 예측값(Predicted): \\n', predicted.detach().cpu().numpy())\n",
    "    print('실제값(Y): \\n', Y.cpu().numpy())\n",
    "    print('정확도(Accuracy): ', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
