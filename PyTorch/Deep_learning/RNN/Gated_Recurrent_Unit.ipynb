{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 게이트 순환 유닛(Gated Recurrent Unit, GRU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU(Gated Recurrent Unit)는 LSTM의 장기 의존성 문제에 대한 장점을 유지하면서 은닉 상태를 업데이트하는 계산을 줄여 복잡성을 낮춘 모델\n",
    "\n",
    "LSTM에 비해 구조적으로 단순하여, 빠른 학습 시간과 낮은 계산 복잡성을 가짐\n",
    "\n",
    "LSTM에 비해 성능면에서 항상 최선은 아님\n",
    "\n",
    "기존의 LSTM의 최적의 하이퍼패러미터를 찾았다면 LSTM이 더 나은 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 데이터 양이 적을 때는 매개 변수의 양이 적은 GRU가 더 나은 성능을 보이고\n",
    "\n",
    "데이터 양이 많을 때는 LSTM이 더 나은 성능을 보임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU(Gated Recurrent Unit) 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](gru.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ r_t = \\sigma (W_{xr} x_t + W_{hr} h_{t-1} + b_r) $\n",
    "\n",
    "$ z_t = \\sigma (W_{xz} x_t + W_{hz} h_{t-1} + b_z) $\n",
    "\n",
    "$ g_t = tanh (W_{hg}(r_t \\circ h_{t-1}) + W_{xg} x_t + b_g) $\n",
    "\n",
    "$ h_t = (1 - z_t) \\circ g_t + z_t \\circ h_{t-1} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU는 리셋 게이트, 업데이트 게이트 두 가지 게이트를 가짐\n",
    "\n",
    "리셋 게이트는 이전 시점의 정보를 적절히 리셋시키기 위한 게이트\n",
    "\n",
    "업데이트 게이트는 이전 시점과 현재 시점의 정보의 최신화 비율을 결정하는 게이트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch에서 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM과 마찬가지로 RNN 셀을 GRU 셀로 바꿔주면 됨\n",
    "\n",
    "nn.RNN(input_dim, hidden_size, batch_fisrt=True)\n",
    "\n",
    "->\n",
    "\n",
    "nn.GRU(input_dim, hidden_size, batch_fisrt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 10\n",
    "hidden_dim = 100\n",
    "layer_dim = 1\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(GRUModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        out, hn = self.gru(x, h0.detach())\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "model = GRUModel(input_dim, hidden_dim, layer_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_dim = 7\n",
    "batch_size = 2\n",
    "input_data = torch.randn(batch_size, seq_dim, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "output = model(input_data)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
