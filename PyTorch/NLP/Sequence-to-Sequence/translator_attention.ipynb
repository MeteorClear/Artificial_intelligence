{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 어텐션 메커니즘을 이용한 번역기 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2Seq을 사용한 번역기에서 어텐션 메커니즘을 추가하여 기계 번역기 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import urllib3\n",
    "import zipfile\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 총 데이터의 양\n",
    "num_samples = 230000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    # 프랑스어 악센트(accent) 삭제\n",
    "    # 예시 : 'déjà diné' -> deja dine\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sent):\n",
    "    # 악센트 삭제 함수 호출\n",
    "    sent = unicode_to_ascii(sent.lower())\n",
    "\n",
    "    # 단어와 구두점 사이에 공백을 만듭니다.\n",
    "    # Ex) \"he is a boy.\" => \"he is a boy .\"\n",
    "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
    "\n",
    "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환합니다.\n",
    "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
    "\n",
    "    # 다수 개의 공백을 하나의 공백으로 치환\n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed_data():\n",
    "    encoder_input, decoder_input, decoder_target = [], [], []\n",
    "\n",
    "    with open(\"fra.txt\", \"r\") as lines:\n",
    "        for i, line in enumerate(lines):\n",
    "            # source 데이터와 target 데이터 분리\n",
    "            src_line, tar_line, _ = line.strip().split('\\t')\n",
    "\n",
    "            # source 데이터 전처리\n",
    "            src_line = [w for w in preprocess_sentence(src_line).split()]\n",
    "\n",
    "            # target 데이터 전처리\n",
    "            tar_line = preprocess_sentence(tar_line)\n",
    "            tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n",
    "            tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n",
    "\n",
    "            encoder_input.append(src_line)\n",
    "            decoder_input.append(tar_line_in)\n",
    "            decoder_target.append(tar_line_out)\n",
    "\n",
    "            if i == num_samples - 1:\n",
    "                break\n",
    "\n",
    "    return encoder_input, decoder_input, decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 전 영어 문장 : Have you had dinner?\n",
      "전처리 후 영어 문장 : have you had dinner ?\n",
      "전처리 전 프랑스어 문장 : Avez-vous déjà diné?\n",
      "전처리 후 프랑스어 문장 : avez vous deja dine ?\n"
     ]
    }
   ],
   "source": [
    "# 전처리 테스트\n",
    "en_sent = u\"Have you had dinner?\"\n",
    "fr_sent = u\"Avez-vous déjà diné?\"\n",
    "\n",
    "print('전처리 전 영어 문장 :', en_sent)\n",
    "print('전처리 후 영어 문장 :',preprocess_sentence(en_sent))\n",
    "print('전처리 전 프랑스어 문장 :', fr_sent)\n",
    "print('전처리 후 프랑스어 문장 :', preprocess_sentence(fr_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코더의 입력 : [['go', '.'], ['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.']]\n",
      "디코더의 입력 : [['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'en', 'route', '!'], ['<sos>', 'bouge', '!'], ['<sos>', 'salut', '!']]\n",
      "디코더의 레이블 : [['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['en', 'route', '!', '<eos>'], ['bouge', '!', '<eos>'], ['salut', '!', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "# 전처리 수행\n",
    "# 훈련 시 사용할 디코더의 입력 시퀀스와 출력 시퀀스를 따로 분리하여 저장\n",
    "# 입력 시퀀스에는 시작을 의미하는 토큰인 <sos>를 추가\n",
    "# 출력 시퀀스에는 종료를 의미하는 토큰인 <eos>를 추가\n",
    "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n",
    "print('인코더의 입력 :',sents_en_in[:5])\n",
    "print('디코더의 입력 :',sents_fra_in[:5])\n",
    "print('디코더의 레이블 :',sents_fra_out[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 과정에서는 이전 시점의 디코더 셀의 출력을 현재 시점의 디코더 셀의 입력으로 넣어주지 않고, \n",
    "\n",
    "이전 시점의 실제값을 현재 시점의 디코더 셀의 입력값으로 하는 방법을 사용\n",
    "\n",
    "그 이유는 이전 시점의 디코더 셀의 예측이 틀렸는데 이를 현재 시점의 디코더 셀의 입력으로 사용하면,\n",
    "\n",
    "현재 시점의 디코더 셀의 예측도 잘못될 가능성이 높고 이는 연쇄 작용으로 디코더 전체의 예측을 어렵게 함\n",
    "\n",
    "이런 상황이 반복되면 훈련 시간이 느려짐\n",
    "\n",
    "이 상황을 원하지 않는다면 이전 시점의 디코더 셀의 예측값 대신 실제값을 현재 시점의 디코더 셀의 입력으로 사용하는 방법을 사용할 수 있음\n",
    "\n",
    "이와 같이 RNN의 모든 시점에 대해서 이전 시점의 예측값 대신 실제값을 입력으로 주는 방법을 교사 강요라고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 집합(Vocabulary) 생성 함수\n",
    "# 패딩 토큰을 위한 <PAD> 토큰은 0번, OOV에 대응하기 위한 <UNK> 토큰은 1번에 할당\n",
    "# 빈도수가 가장 높은 단어는 정수가 2번, 빈도수가 두번 째로 많은 단어는 정수 3번이 할당\n",
    "def build_vocab(sents):\n",
    "    word_list = []\n",
    "\n",
    "    for sent in sents:\n",
    "        for word in sent:\n",
    "            word_list.append(word)\n",
    "\n",
    "    # 각 단어별 등장 빈도를 계산하여 등장 빈도가 높은 순서로 정렬\n",
    "    word_counts = Counter(word_list)\n",
    "    vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    word_to_index = {}\n",
    "    word_to_index['<PAD>'] = 0\n",
    "    word_to_index['<UNK>'] = 1\n",
    "\n",
    "    # 등장 빈도가 높은 단어일수록 낮은 정수를 부여\n",
    "    for index, word in enumerate(vocab) :\n",
    "        word_to_index[word] = index + 2\n",
    "\n",
    "    return word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어 집합의 크기 : 15516, 프랑스어 단어 집합의 크기 : 25011\n"
     ]
    }
   ],
   "source": [
    "# 구현 방식에 따라서는 하나의 단어 집합으로 만들어도 상관없음\n",
    "# 영어 단어 집합\n",
    "src_vocab = build_vocab(sents_en_in)\n",
    "# 프랑스어 단어 집합\n",
    "tar_vocab = build_vocab(sents_fra_in + sents_fra_out)\n",
    "\n",
    "src_vocab_size = len(src_vocab)\n",
    "tar_vocab_size = len(tar_vocab)\n",
    "print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_src = {v: k for k, v in src_vocab.items()}\n",
    "index_to_tar = {v: k for k, v in tar_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수로부터 단어를 얻는 딕셔너리 생성\n",
    "def texts_to_sequences(sents, word_to_index):\n",
    "    encoded_X_data = []\n",
    "    for sent in tqdm(sents):\n",
    "        index_sequences = []\n",
    "        for word in sent:\n",
    "            try:\n",
    "                index_sequences.append(word_to_index[word])\n",
    "            except KeyError:\n",
    "                index_sequences.append(word_to_index['<UNK>'])\n",
    "        encoded_X_data.append(index_sequences)\n",
    "    return encoded_X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230000/230000 [00:00<00:00, 364222.23it/s]\n",
      "100%|██████████| 230000/230000 [00:00<00:00, 330437.88it/s]\n",
      "100%|██████████| 230000/230000 [00:00<00:00, 295360.23it/s]\n"
     ]
    }
   ],
   "source": [
    "encoder_input = texts_to_sequences(sents_en_in, src_vocab)\n",
    "decoder_input = texts_to_sequences(sents_fra_in, tar_vocab)\n",
    "decoder_target = texts_to_sequences(sents_fra_out, tar_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [50, 2]\n",
      "Index: 1, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [50, 2]\n",
      "Index: 2, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [50, 2]\n",
      "Index: 3, 정수 인코딩 전: ['go', '.'], 정수 인코딩 후: [50, 2]\n",
      "Index: 4, 정수 인코딩 전: ['hi', '.'], 정수 인코딩 후: [2488, 2]\n",
      "Index: 5, 정수 인코딩 전: ['hi', '.'], 정수 인코딩 후: [2488, 2]\n",
      "Index: 6, 정수 인코딩 전: ['run', '!'], 정수 인코딩 후: [406, 116]\n",
      "Index: 7, 정수 인코딩 전: ['run', '!'], 정수 인코딩 후: [406, 116]\n",
      "Index: 8, 정수 인코딩 전: ['run', '!'], 정수 인코딩 후: [406, 116]\n",
      "Index: 9, 정수 인코딩 전: ['run', '!'], 정수 인코딩 후: [406, 116]\n"
     ]
    }
   ],
   "source": [
    "# 상위 샘플에 대해서 정수 인코딩 전, 후 문장 출력\n",
    "# 인코더 입력이므로 <sos>나 <eos>가 없음\n",
    "for i, (item1, item2) in zip(range(10), zip(sents_en_in, encoder_input)):\n",
    "    print(f\"Index: {i}, 정수 인코딩 전: {item1}, 정수 인코딩 후: {item2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩 함수\n",
    "def pad_sequences(sentences, max_len=None):\n",
    "    # 최대 길이 값이 주어지지 않을 경우 데이터 내 최대 길이로 패딩\n",
    "    if max_len is None:\n",
    "        max_len = max([len(sentence) for sentence in sentences])\n",
    "\n",
    "    features = np.zeros((len(sentences), max_len), dtype=int)\n",
    "    for index, sentence in enumerate(sentences):\n",
    "        if len(sentence) != 0:\n",
    "            features[index, :len(sentence)] = np.array(sentence)[:max_len]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input)\n",
    "decoder_input = pad_sequences(decoder_input)\n",
    "decoder_target = pad_sequences(decoder_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코더의 입력의 크기(shape) : (230000, 20)\n",
      "디코더의 입력의 크기(shape) : (230000, 28)\n",
      "디코더의 레이블의 크기(shape) : (230000, 28)\n"
     ]
    }
   ],
   "source": [
    "print('인코더의 입력의 크기(shape) :',encoder_input.shape)\n",
    "print('디코더의 입력의 크기(shape) :',decoder_input.shape)\n",
    "print('디코더의 레이블의 크기(shape) :',decoder_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤 시퀀스 : [ 56600 182004 155052 ...   5579 207840 138745]\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터를 분리하기 전 데이터를 섞음\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print('랜덤 시퀀스 :',indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'deliberately', 'broke', 'the', 'glass', '.', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "['<sos>', 'il', 'a', 'deliberement', 'brise', 'la', 'vitre', '.', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "['il', 'a', 'deliberement', 'brise', 'la', 'vitre', '.', '<eos>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "print([index_to_src[word] for word in encoder_input[10000]])\n",
    "print([index_to_tar[word] for word in decoder_input[10000]])\n",
    "print([index_to_tar[word] for word in decoder_target[10000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터의 개수 : 3300\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(33000*0.1)\n",
    "print('검증 데이터의 개수 :',n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 source 데이터의 크기 : (226700, 20)\n",
      "훈련 target 데이터의 크기 : (226700, 28)\n",
      "훈련 target 레이블의 크기 : (226700, 28)\n",
      "테스트 source 데이터의 크기 : (3300, 20)\n",
      "테스트 target 데이터의 크기 : (3300, 28)\n",
      "테스트 target 레이블의 크기 : (3300, 28)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 source 데이터의 크기 :',encoder_input_train.shape)\n",
    "print('훈련 target 데이터의 크기 :',decoder_input_train.shape)\n",
    "print('훈련 target 레이블의 크기 :',decoder_target_train.shape)\n",
    "print('테스트 source 데이터의 크기 :',encoder_input_test.shape)\n",
    "print('테스트 target 데이터의 크기 :',decoder_input_test.shape)\n",
    "print('테스트 target 레이블의 크기 :',decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 번역기 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "hidden_units = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder 클래스 Seq2Seq 기계 번역기와 동일\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, src_vocab_size, embedding_dim, hidden_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(src_vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_units, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape == (batch_size, seq_len, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        # hidden.shape == (1, batch_size, hidden_units), cell.shape == (1, batch_size, hidden_units)\n",
    "        outputs, (hidden, cell) = self.lstm(x)\n",
    "        return outputs, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder 클래스, Seq2Seq 기계 번역기와 완전히 달라짐, 어텐션 메커니즘 자체가 디코더 단에서 시작되기 때문\n",
    "# 디코더의 은닉 상태와 인코더의 모든 시점의 은닉 상태간의 내적(dot product)를 통해서 어텐션 스코어(attention_scores)를 계산\n",
    "# 어텐션 스코어를 소프트맥스(softmax) 함수를 통과시켜 어텐션 가중치(attention_weights)를 계산\n",
    "# 어텐션 가중치는 어텐션 메커니즘에서 Value에 해당하는 인코더의 모든 시점의 은닉 상태와 다시 각각 곱하고 모두 더해 컨텍스트 벡터(context_vector)를 계산\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, tar_vocab_size, embedding_dim, hidden_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(tar_vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim + hidden_units, hidden_units, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_units, tar_vocab_size)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, x, encoder_outputs, hidden, cell):\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # Dot product attention\n",
    "        # attention_scores.shape: (batch_size, source_seq_len, 1)\n",
    "        attention_scores = torch.bmm(encoder_outputs, hidden.transpose(0, 1).transpose(1, 2))\n",
    "\n",
    "        # attention_weights.shape: (batch_size, source_seq_len, 1)\n",
    "        attention_weights = self.softmax(attention_scores)\n",
    "\n",
    "        # context_vector.shape: (batch_size, 1, hidden_units)\n",
    "        context_vector = torch.bmm(attention_weights.transpose(1, 2), encoder_outputs)\n",
    "\n",
    "        # Repeat context_vector to match seq_len\n",
    "        # context_vector_repeated.shape: (batch_size, target_seq_len, hidden_units)\n",
    "        seq_len = x.shape[1]\n",
    "        context_vector_repeated = context_vector.repeat(1, seq_len, 1)\n",
    "\n",
    "        # Concatenate context vector and embedded input\n",
    "        # x.shape: (batch_size, target_seq_len, embedding_dim + hidden_units)\n",
    "        x = torch.cat((x, context_vector_repeated), dim=2)\n",
    "\n",
    "        # output.shape: (batch_size, target_seq_len, hidden_units)\n",
    "        # hidden.shape: (1, batch_size, hidden_units)\n",
    "        # cell.shape: (1, batch_size, hidden_units)\n",
    "        output, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
    "\n",
    "        # output.shape: (batch_size, target_seq_len, tar_vocab_size)\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq2Seq 클래스, Seq2Seq 기계 번역기와 동일\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        encoder_outputs, hidden, cell = self.encoder(src)\n",
    "        output, _, _ = self.decoder(trg, encoder_outputs, hidden, cell)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(src_vocab_size, embedding_dim, hidden_units)\n",
    "decoder = Decoder(tar_vocab_size, embedding_dim, hidden_units)\n",
    "model = Seq2Seq(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(15516, 256, padding_idx=0)\n",
      "    (lstm): LSTM(256, 256, batch_first=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(25011, 256, padding_idx=0)\n",
      "    (lstm): LSTM(512, 256, batch_first=True)\n",
      "    (fc): Linear(in_features=256, out_features=25011, bias=True)\n",
      "    (softmax): Softmax(dim=2)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, dataloader, loss_function, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for encoder_inputs, decoder_inputs, decoder_targets in dataloader:\n",
    "            encoder_inputs = encoder_inputs.to(device)\n",
    "            decoder_inputs = decoder_inputs.to(device)\n",
    "            decoder_targets = decoder_targets.to(device)\n",
    "\n",
    "            # 순방향 전파\n",
    "            # outputs.shape == (batch_size, seq_len, tar_vocab_size)\n",
    "            outputs = model(encoder_inputs, decoder_inputs)\n",
    "\n",
    "            # 손실 계산\n",
    "            # outputs.view(-1, outputs.size(-1))의 shape는 (batch_size * seq_len, tar_vocab_size)\n",
    "            # decoder_targets.view(-1)의 shape는 (batch_size * seq_len)\n",
    "            loss = loss_function(outputs.view(-1, outputs.size(-1)), decoder_targets.view(-1))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # 정확도 계산 (패딩 토큰 제외)\n",
    "            mask = decoder_targets != 0\n",
    "            total_correct += ((outputs.argmax(dim=-1) == decoder_targets) * mask).sum().item()\n",
    "            total_count += mask.sum().item()\n",
    "\n",
    "    return total_loss / len(dataloader), total_correct / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train_tensor = torch.tensor(encoder_input_train, dtype=torch.long)\n",
    "decoder_input_train_tensor = torch.tensor(decoder_input_train, dtype=torch.long)\n",
    "decoder_target_train_tensor = torch.tensor(decoder_target_train, dtype=torch.long)\n",
    "\n",
    "encoder_input_test_tensor = torch.tensor(encoder_input_test, dtype=torch.long)\n",
    "decoder_input_test_tensor = torch.tensor(decoder_input_test, dtype=torch.long)\n",
    "decoder_target_test_tensor = torch.tensor(decoder_target_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 및 데이터로더 생성\n",
    "batch_size = 128\n",
    "\n",
    "train_dataset = TensorDataset(encoder_input_train_tensor, decoder_input_train_tensor, decoder_target_train_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_dataset = TensorDataset(encoder_input_test_tensor, decoder_input_test_tensor, decoder_target_test_tensor)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(15516, 256, padding_idx=0)\n",
       "    (lstm): LSTM(256, 256, batch_first=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(25011, 256, padding_idx=0)\n",
       "    (lstm): LSTM(512, 256, batch_first=True)\n",
       "    (fc): Linear(in_features=256, out_features=25011, bias=True)\n",
       "    (softmax): Softmax(dim=2)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 설정\n",
    "num_epochs = 20\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20 | Train Loss: 2.0988 | Train Acc: 0.6004 | Valid Loss: 2.1996 | Valid Acc: 0.5902\n",
      "Validation loss improved from inf to 2.1996. 체크포인트를 저장합니다.\n",
      "Epoch: 2/20 | Train Loss: 1.4554 | Train Acc: 0.6880 | Valid Loss: 1.7006 | Valid Acc: 0.6586\n",
      "Validation loss improved from 2.1996 to 1.7006. 체크포인트를 저장합니다.\n",
      "Epoch: 3/20 | Train Loss: 1.1230 | Train Acc: 0.7390 | Valid Loss: 1.4847 | Valid Acc: 0.6921\n",
      "Validation loss improved from 1.7006 to 1.4847. 체크포인트를 저장합니다.\n",
      "Epoch: 4/20 | Train Loss: 0.9138 | Train Acc: 0.7738 | Valid Loss: 1.3823 | Valid Acc: 0.7051\n",
      "Validation loss improved from 1.4847 to 1.3823. 체크포인트를 저장합니다.\n",
      "Epoch: 5/20 | Train Loss: 0.7707 | Train Acc: 0.8023 | Valid Loss: 1.3279 | Valid Acc: 0.7192\n",
      "Validation loss improved from 1.3823 to 1.3279. 체크포인트를 저장합니다.\n",
      "Epoch: 6/20 | Train Loss: 0.6731 | Train Acc: 0.8236 | Valid Loss: 1.2998 | Valid Acc: 0.7245\n",
      "Validation loss improved from 1.3279 to 1.2998. 체크포인트를 저장합니다.\n",
      "Epoch: 7/20 | Train Loss: 0.6014 | Train Acc: 0.8385 | Valid Loss: 1.2986 | Valid Acc: 0.7271\n",
      "Validation loss improved from 1.2998 to 1.2986. 체크포인트를 저장합니다.\n",
      "Epoch: 8/20 | Train Loss: 0.5395 | Train Acc: 0.8528 | Valid Loss: 1.2929 | Valid Acc: 0.7318\n",
      "Validation loss improved from 1.2986 to 1.2929. 체크포인트를 저장합니다.\n",
      "Epoch: 9/20 | Train Loss: 0.4902 | Train Acc: 0.8647 | Valid Loss: 1.2985 | Valid Acc: 0.7323\n",
      "Epoch: 10/20 | Train Loss: 0.4528 | Train Acc: 0.8732 | Valid Loss: 1.3080 | Valid Acc: 0.7336\n",
      "Epoch: 11/20 | Train Loss: 0.4139 | Train Acc: 0.8823 | Valid Loss: 1.3155 | Valid Acc: 0.7387\n",
      "Epoch: 12/20 | Train Loss: 0.3839 | Train Acc: 0.8891 | Valid Loss: 1.3408 | Valid Acc: 0.7361\n",
      "Epoch: 13/20 | Train Loss: 0.3591 | Train Acc: 0.8951 | Valid Loss: 1.3487 | Valid Acc: 0.7369\n",
      "Epoch: 14/20 | Train Loss: 0.3359 | Train Acc: 0.9001 | Valid Loss: 1.3700 | Valid Acc: 0.7374\n",
      "Epoch: 15/20 | Train Loss: 0.3156 | Train Acc: 0.9059 | Valid Loss: 1.3910 | Valid Acc: 0.7356\n",
      "Epoch: 16/20 | Train Loss: 0.2970 | Train Acc: 0.9108 | Valid Loss: 1.4067 | Valid Acc: 0.7358\n",
      "Epoch: 17/20 | Train Loss: 0.2809 | Train Acc: 0.9142 | Valid Loss: 1.4187 | Valid Acc: 0.7379\n",
      "Epoch: 18/20 | Train Loss: 0.2659 | Train Acc: 0.9182 | Valid Loss: 1.4416 | Valid Acc: 0.7384\n",
      "Epoch: 19/20 | Train Loss: 0.2568 | Train Acc: 0.9199 | Valid Loss: 1.4710 | Valid Acc: 0.7353\n",
      "Epoch: 20/20 | Train Loss: 0.2456 | Train Acc: 0.9232 | Valid Loss: 1.4785 | Valid Acc: 0.7362\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 훈련 모드\n",
    "    model.train()\n",
    "\n",
    "    for encoder_inputs, decoder_inputs, decoder_targets in train_dataloader:\n",
    "        encoder_inputs = encoder_inputs.to(device)\n",
    "        decoder_inputs = decoder_inputs.to(device)\n",
    "        decoder_targets = decoder_targets.to(device)\n",
    "\n",
    "        # 기울기 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 순방향 전파\n",
    "        # outputs.shape == (batch_size, seq_len, tar_vocab_size)\n",
    "        outputs = model(encoder_inputs, decoder_inputs)\n",
    "\n",
    "        # 손실 계산 및 역방향 전파\n",
    "        # outputs.view(-1, outputs.size(-1))의 shape는 (batch_size * seq_len, tar_vocab_size)\n",
    "        # decoder_targets.view(-1)의 shape는 (batch_size * seq_len)\n",
    "        loss = loss_function(outputs.view(-1, outputs.size(-1)), decoder_targets.view(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        # 가중치 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss, train_acc = evaluation(model, train_dataloader, loss_function, device)\n",
    "    valid_loss, valid_acc = evaluation(model, valid_dataloader, loss_function, device)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Valid Loss: {valid_loss:.4f} | Valid Acc: {valid_acc:.4f}')\n",
    "\n",
    "    # 검증 손실이 최소일 때 체크포인트 저장\n",
    "    if valid_loss < best_val_loss:\n",
    "        print(f'Validation loss improved from {best_val_loss:.4f} to {valid_loss:.4f}. 체크포인트를 저장합니다.')\n",
    "        best_val_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best_model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(15516, 256, padding_idx=0)\n",
       "    (lstm): LSTM(256, 256, batch_first=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(25011, 256, padding_idx=0)\n",
       "    (lstm): LSTM(512, 256, batch_first=True)\n",
       "    (fc): Linear(in_features=256, out_features=25011, bias=True)\n",
       "    (softmax): Softmax(dim=2)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 로드\n",
    "model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model validation loss: 1.2929\n",
      "Best model validation accuracy: 0.7318\n"
     ]
    }
   ],
   "source": [
    "# 검증 데이터에 대한 정확도와 손실 계산\n",
    "val_loss, val_accuracy = evaluation(model, valid_dataloader, loss_function, device)\n",
    "\n",
    "print(f'Best model validation loss: {val_loss:.4f}')\n",
    "print(f'Best model validation accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(tar_vocab['<sos>'])\n",
    "print(tar_vocab['<eos>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seq2seq 기계 번역기 동작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seq2seq는 훈련 과정(교사 강요)과 테스트 과정에서의 동작 방식이 다름\n",
    "\n",
    "테스트 과정을 위해 모델을 다시 설계해주어야 함, 특히 디코더를 수정해야 함\n",
    "\n",
    "전체적인 번역 단계는 다음과 같음\n",
    "  1. 번역하고자 하는 입력 문장이 인코더로 입력되어 인코더의 마지막 시점의 은닉 상태와 셀 상태를 얻음\n",
    "  2. 인코더의 은닉 상태와 셀 상태, 그리고 토큰 \\<sos\\>를 디코더로 보냄\n",
    "  3. 디코더가 토큰 \\<eos\\>가 나올 때까지 다음 단어를 예측하는 행동을 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_src = {v: k for k, v in src_vocab.items()}\n",
    "index_to_tar = {v: k for k, v in tar_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq_to_src(input_seq):\n",
    "    sentence = ''\n",
    "    for encoded_word in input_seq:\n",
    "        if(encoded_word != 0):\n",
    "            sentence = sentence + index_to_src[encoded_word] + ' '\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq_to_tar(input_seq):\n",
    "    sentence = ''\n",
    "    for encoded_word in input_seq:\n",
    "        if(encoded_word != 0 and encoded_word != tar_vocab['<sos>'] and encoded_word != tar_vocab['<eos>']):\n",
    "            sentence = sentence + index_to_tar[encoded_word] + ' '\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  10   12 4680    2    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "[   3   18   10 8677    2    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[  18   10 8677    2    4    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_test[25])\n",
    "print(decoder_input_test[25])\n",
    "print(decoder_target_test[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, max_output_len, int_to_src_token, int_to_tar_token):\n",
    "    encoder_inputs = torch.tensor(input_seq, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    # 인코더의 초기 상태 설정\n",
    "    encoder_outputs, hidden, cell = model.encoder(encoder_inputs)\n",
    "\n",
    "    # 시작 토큰 <sos>을 디코더의 첫 입력으로 설정\n",
    "    # unsqueeze(0)는 배치 차원을 추가하기 위함.\n",
    "    decoder_input = torch.tensor([3], dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    decoded_tokens = []\n",
    "\n",
    "    # for문을 도는 것 == 디코더의 각 시점\n",
    "    for _ in range(max_output_len):\n",
    "        output, hidden, cell = model.decoder(decoder_input, encoder_outputs, hidden, cell)\n",
    "\n",
    "        # 소프트맥스 회귀를 수행. 예측 단어의 인덱스\n",
    "        output_token = output.argmax(dim=-1).item()\n",
    "\n",
    "        # 종료 토큰 <eos>\n",
    "        if output_token == 4:\n",
    "            break\n",
    "\n",
    "        # 각 시점의 단어(정수)는 decoded_tokens에 누적하였다가 최종 번역 시퀀스로 리턴합니다.\n",
    "        decoded_tokens.append(output_token)\n",
    "\n",
    "        # 현재 시점의 예측. 다음 시점의 입력으로 사용된다.\n",
    "        decoder_input = torch.tensor([output_token], dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    return ' '.join(int_to_tar_token[token] for token in decoded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력문장 : tom wants to work . \n",
      "정답문장 : tom veut travailler . \n",
      "번역문장 : tom veut travailler .\n",
      "--------------------------------------------------\n",
      "입력문장 : i couldn t do that even if i wanted to . \n",
      "정답문장 : je ne pourrais pas faire cela meme si je le voulais . \n",
      "번역문장 : je ne pourrais pas faire ca si je voulais .\n",
      "--------------------------------------------------\n",
      "입력문장 : our only daughter died of cancer . \n",
      "정답문장 : notre fille unique est decedee d un cancer . \n",
      "번역문장 : notre fille unique est morte d un cancer .\n",
      "--------------------------------------------------\n",
      "입력문장 : i know how busy you ve been . \n",
      "정답문장 : je sais combien tu as ete occupee . \n",
      "번역문장 : je sais combien vous avez ete occupe .\n",
      "--------------------------------------------------\n",
      "입력문장 : how old is your house ? \n",
      "정답문장 : quel age a votre maison ? \n",
      "번역문장 : quel age a ta maison ?\n",
      "--------------------------------------------------\n",
      "입력문장 : all three were killed . \n",
      "정답문장 : tous les trois furent tues . \n",
      "번역문장 : toutes les trois furent tuees .\n",
      "--------------------------------------------------\n",
      "입력문장 : the evidence is fairly conclusive . \n",
      "정답문장 : la preuve est assez concluante . \n",
      "번역문장 : la preuve est assez concluante .\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3, 50, 100, 300, 1000, 1500, 3000]:\n",
    "    input_seq = encoder_input_train[seq_index]\n",
    "    translated_text = decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, 20, index_to_src, index_to_tar)\n",
    "\n",
    "    print(\"입력문장 :\",seq_to_src(encoder_input_train[seq_index]))\n",
    "    print(\"정답문장 :\",seq_to_tar(decoder_input_train[seq_index]))\n",
    "    print(\"번역문장 :\",translated_text)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력문장 : ask him whether she is at home or not . \n",
      "정답문장 : demande lui si elle est a la maison ou pas . \n",
      "번역문장 : a la maison lui elle est elle donc elle est a la ou pas .\n",
      "--------------------------------------------------\n",
      "입력문장 : tom should learn french . \n",
      "정답문장 : tom devrait apprendre le francais . \n",
      "번역문장 : tom devrait apprendre le francais .\n",
      "--------------------------------------------------\n",
      "입력문장 : i plead ignorance . \n",
      "정답문장 : j invoque l ignorance . \n",
      "번역문장 : je plaide l ignorance .\n",
      "--------------------------------------------------\n",
      "입력문장 : you don t look so busy . \n",
      "정답문장 : tu ne sembles pas si occupe . \n",
      "번역문장 : vous n avez pas l air si occupe .\n",
      "--------------------------------------------------\n",
      "입력문장 : you re after me . \n",
      "정답문장 : tu es apres moi . \n",
      "번역문장 : vous etes apres moi .\n",
      "--------------------------------------------------\n",
      "입력문장 : you re very busy . \n",
      "정답문장 : vous etes tres occupe . \n",
      "번역문장 : vous etes tres occupes .\n",
      "--------------------------------------------------\n",
      "입력문장 : how much is your commission ? \n",
      "정답문장 : quel est le montant de votre commission ? \n",
      "번역문장 : combien coute ton ?\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3, 50, 100, 300, 1001, 1500, 3000]:\n",
    "    input_seq = encoder_input_test[seq_index]\n",
    "    translated_text = decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, 20, index_to_src, index_to_tar)\n",
    "\n",
    "    print(\"입력문장 :\",seq_to_src(encoder_input_test[seq_index]))\n",
    "    print(\"정답문장 :\",seq_to_tar(decoder_input_test[seq_index]))\n",
    "    print(\"번역문장 :\",translated_text)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
