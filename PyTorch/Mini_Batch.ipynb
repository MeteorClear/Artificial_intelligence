{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Batch / Minibatch Gradient Descent / Data Load / Custom Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini Batch and Batch Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 수십만개 이상이라면 전체 데이터에 대해서 경사 하강법을 수행하는 것은 매우 느릴 뿐만 아니라 많은 계산량이 필요\n",
    "\n",
    "`Mini Batch` : 전체 데이터를 더 작은 단위로 나누어서 학습하는 단위\n",
    "\n",
    "미니 배치 학습을 하게되면 미니 배치만큼만 가져가서 미니 배치에 대한 대한 cost를 계산하고, 경사 하강법을 수행\n",
    "\n",
    "다음 미니 배치를 가져가서 경사 하강법을 수행하고 마지막 미니 배치까지 이를 반복\n",
    "\n",
    "전체 데이터에 대한 학습이 1회 끝나면 1 Epoch(에폭)이 끝남\n",
    "\n",
    "`Epoch` : 전체 훈련 데이터가 학습에 한 번 사용된 주기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미니 배치 학습에서는 미니 배치의 개수만큼 경사 하강법을 수행해야 전체 데이터가 한 번 전부 사용되어 1 에포크(Epoch)가 됨\n",
    "\n",
    "미니 배치의 개수는 결국 미니 배치의 크기를 몇으로 하느냐에 따라서 달라짐\n",
    "\n",
    "`batch size` : mini batch의 크기\n",
    "\n",
    "`batch gradient descent` : 전체 데이터에 대해서 한 번에 경사 하강법을 수행하는 방법, 전체 데이터를 사용하므로 가중치 값이 최적값에 수렴하는 과정이 매우 안정적, 계산량이 너무 많음\n",
    "\n",
    "`minibatch gradient descent` : 미니 배치 단위로 경사 하강법을 수행하는 방법, 전체 데이터의 일부만을 보고 수행하므로 최적값으로 수렴하는데 헤맴, 훈련 속도가 빠름\n",
    "\n",
    "배치 크기는 보통 2의 제곱수를 사용, CPU와 GPU의 메모리가 2의 배수이므로 배치크기가 2의 제곱수일 경우에 데이터 송수신의 효율을 높일 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration(이터레이션)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Iteration` : 한 번의 Epoch 내에서 이루어지는 매개변수인 가중치 W와 b의 업데이트 횟수\n",
    "\n",
    "전체 데이터가 2000이고 배치 크기가 200이면 이터레이션은 10\n",
    "\n",
    "에폭당 매겨변수 업데이트가 10번 이루어짐을 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이토치에서는 데이터를 좀 더 쉽게 다룰 수 있도록 유용한 도구로서 데이터셋(Dataset)과 데이터로더(DataLoader)를 제공\n",
    "\n",
    "미니 배치 학습, 데이터 셔플(shuffle), 병렬 처리 기능이 포함됨\n",
    "\n",
    "기본적인 사용 방법은 Dataset을 정의하고, 이를 DataLoader에 전달하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
    "from torch.utils.data import DataLoader # 데이터로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorDataset은 기본적으로 텐서를 입력으로 받습니다. 텐서 형태로 데이터를 정의\n",
    "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
    "                               [93,  88,  93], \n",
    "                               [89,  91,  90], \n",
    "                               [96,  98,  100],   \n",
    "                               [73,  66,  70]])  \n",
    "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
    "dataset = TensorDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이토치의 데이터셋을 만들었다면 데이터로더를 사용 가능\n",
    "\n",
    "데이터로더는 기본적으로 2개의 인자를 입력, 데이터셋, 미니배치 크기\n",
    "\n",
    "많이 사용되는 인자로 shuffle이 있음 shuffle=True를 선택하면 Epoch마다 데이터셋을 섞어서 데이터가 학습되는 순서를 바꿈\n",
    "\n",
    "모델이 데이터셋의 순서에 익숙해지는 것을 방지하여 학습할 때는 이 옵션을 True를 주는 것을 권장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(3,1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[tensor([[93., 88., 93.],\n",
      "        [89., 91., 90.]]), tensor([[185.],\n",
      "        [180.]])]\n",
      "Epoch    0/20 Batch 1/3 Cost: 50238.281250\n",
      "1\n",
      "[tensor([[73., 66., 70.],\n",
      "        [73., 80., 75.]]), tensor([[142.],\n",
      "        [152.]])]\n",
      "Epoch    0/20 Batch 2/3 Cost: 8322.404297\n",
      "2\n",
      "[tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n",
      "Epoch    0/20 Batch 3/3 Cost: 6578.057617\n",
      "0\n",
      "[tensor([[93., 88., 93.],\n",
      "        [73., 66., 70.]]), tensor([[185.],\n",
      "        [142.]])]\n",
      "Epoch    1/20 Batch 1/3 Cost: 1125.345093\n",
      "1\n",
      "[tensor([[ 73.,  80.,  75.],\n",
      "        [ 96.,  98., 100.]]), tensor([[152.],\n",
      "        [196.]])]\n",
      "Epoch    1/20 Batch 2/3 Cost: 245.946228\n",
      "2\n",
      "[tensor([[89., 91., 90.]]), tensor([[180.]])]\n",
      "Epoch    1/20 Batch 3/3 Cost: 89.446121\n",
      "0\n",
      "[tensor([[89., 91., 90.],\n",
      "        [73., 66., 70.]]), tensor([[180.],\n",
      "        [142.]])]\n",
      "Epoch    2/20 Batch 1/3 Cost: 55.478935\n",
      "1\n",
      "[tensor([[ 93.,  88.,  93.],\n",
      "        [ 96.,  98., 100.]]), tensor([[185.],\n",
      "        [196.]])]\n",
      "Epoch    2/20 Batch 2/3 Cost: 24.054092\n",
      "2\n",
      "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
      "Epoch    2/20 Batch 3/3 Cost: 3.992069\n",
      "0\n",
      "[tensor([[ 96.,  98., 100.],\n",
      "        [ 89.,  91.,  90.]]), tensor([[196.],\n",
      "        [180.]])]\n",
      "Epoch    3/20 Batch 1/3 Cost: 0.329603\n",
      "1\n",
      "[tensor([[73., 66., 70.],\n",
      "        [93., 88., 93.]]), tensor([[142.],\n",
      "        [185.]])]\n",
      "Epoch    3/20 Batch 2/3 Cost: 28.974880\n",
      "2\n",
      "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
      "Epoch    3/20 Batch 3/3 Cost: 12.232490\n",
      "0\n",
      "[tensor([[93., 88., 93.],\n",
      "        [89., 91., 90.]]), tensor([[185.],\n",
      "        [180.]])]\n",
      "Epoch    4/20 Batch 1/3 Cost: 8.403276\n",
      "1\n",
      "[tensor([[ 96.,  98., 100.],\n",
      "        [ 73.,  80.,  75.]]), tensor([[196.],\n",
      "        [152.]])]\n",
      "Epoch    4/20 Batch 2/3 Cost: 5.813161\n",
      "2\n",
      "[tensor([[73., 66., 70.]]), tensor([[142.]])]\n",
      "Epoch    4/20 Batch 3/3 Cost: 27.595514\n",
      "0\n",
      "[tensor([[ 89.,  91.,  90.],\n",
      "        [ 96.,  98., 100.]]), tensor([[180.],\n",
      "        [196.]])]\n",
      "Epoch    5/20 Batch 1/3 Cost: 6.299822\n",
      "1\n",
      "[tensor([[73., 66., 70.],\n",
      "        [73., 80., 75.]]), tensor([[142.],\n",
      "        [152.]])]\n",
      "Epoch    5/20 Batch 2/3 Cost: 14.756327\n",
      "2\n",
      "[tensor([[93., 88., 93.]]), tensor([[185.]])]\n",
      "Epoch    5/20 Batch 3/3 Cost: 10.220263\n",
      "0\n",
      "[tensor([[93., 88., 93.],\n",
      "        [73., 80., 75.]]), tensor([[185.],\n",
      "        [152.]])]\n",
      "Epoch    6/20 Batch 1/3 Cost: 10.594546\n",
      "1\n",
      "[tensor([[89., 91., 90.],\n",
      "        [73., 66., 70.]]), tensor([[180.],\n",
      "        [142.]])]\n",
      "Epoch    6/20 Batch 2/3 Cost: 9.695044\n",
      "2\n",
      "[tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n",
      "Epoch    6/20 Batch 3/3 Cost: 8.116969\n",
      "0\n",
      "[tensor([[89., 91., 90.],\n",
      "        [93., 88., 93.]]), tensor([[180.],\n",
      "        [185.]])]\n",
      "Epoch    7/20 Batch 1/3 Cost: 6.909569\n",
      "1\n",
      "[tensor([[ 96.,  98., 100.],\n",
      "        [ 73.,  80.,  75.]]), tensor([[196.],\n",
      "        [152.]])]\n",
      "Epoch    7/20 Batch 2/3 Cost: 6.878442\n",
      "2\n",
      "[tensor([[73., 66., 70.]]), tensor([[142.]])]\n",
      "Epoch    7/20 Batch 3/3 Cost: 26.408928\n",
      "0\n",
      "[tensor([[ 96.,  98., 100.],\n",
      "        [ 93.,  88.,  93.]]), tensor([[196.],\n",
      "        [185.]])]\n",
      "Epoch    8/20 Batch 1/3 Cost: 5.998165\n",
      "1\n",
      "[tensor([[73., 66., 70.],\n",
      "        [89., 91., 90.]]), tensor([[142.],\n",
      "        [180.]])]\n",
      "Epoch    8/20 Batch 2/3 Cost: 9.779259\n",
      "2\n",
      "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
      "Epoch    8/20 Batch 3/3 Cost: 14.621848\n",
      "0\n",
      "[tensor([[73., 80., 75.],\n",
      "        [89., 91., 90.]]), tensor([[152.],\n",
      "        [180.]])]\n",
      "Epoch    9/20 Batch 1/3 Cost: 3.493897\n",
      "1\n",
      "[tensor([[ 93.,  88.,  93.],\n",
      "        [ 96.,  98., 100.]]), tensor([[185.],\n",
      "        [196.]])]\n",
      "Epoch    9/20 Batch 2/3 Cost: 10.130724\n",
      "2\n",
      "[tensor([[73., 66., 70.]]), tensor([[142.]])]\n",
      "Epoch    9/20 Batch 3/3 Cost: 21.316448\n",
      "0\n",
      "[tensor([[73., 66., 70.],\n",
      "        [89., 91., 90.]]), tensor([[142.],\n",
      "        [180.]])]\n",
      "Epoch   10/20 Batch 1/3 Cost: 9.669562\n",
      "1\n",
      "[tensor([[ 73.,  80.,  75.],\n",
      "        [ 96.,  98., 100.]]), tensor([[152.],\n",
      "        [196.]])]\n",
      "Epoch   10/20 Batch 2/3 Cost: 13.525709\n",
      "2\n",
      "[tensor([[93., 88., 93.]]), tensor([[185.]])]\n",
      "Epoch   10/20 Batch 3/3 Cost: 11.982736\n",
      "0\n",
      "[tensor([[73., 66., 70.],\n",
      "        [89., 91., 90.]]), tensor([[142.],\n",
      "        [180.]])]\n",
      "Epoch   11/20 Batch 1/3 Cost: 9.629745\n",
      "1\n",
      "[tensor([[93., 88., 93.],\n",
      "        [73., 80., 75.]]), tensor([[185.],\n",
      "        [152.]])]\n",
      "Epoch   11/20 Batch 2/3 Cost: 10.093600\n",
      "2\n",
      "[tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n",
      "Epoch   11/20 Batch 3/3 Cost: 6.962992\n",
      "0\n",
      "[tensor([[73., 80., 75.],\n",
      "        [73., 66., 70.]]), tensor([[152.],\n",
      "        [142.]])]\n",
      "Epoch   12/20 Batch 1/3 Cost: 14.733269\n",
      "1\n",
      "[tensor([[89., 91., 90.],\n",
      "        [93., 88., 93.]]), tensor([[180.],\n",
      "        [185.]])]\n",
      "Epoch   12/20 Batch 2/3 Cost: 6.214371\n",
      "2\n",
      "[tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n",
      "Epoch   12/20 Batch 3/3 Cost: 4.107401\n",
      "0\n",
      "[tensor([[ 96.,  98., 100.],\n",
      "        [ 73.,  66.,  70.]]), tensor([[196.],\n",
      "        [142.]])]\n",
      "Epoch   13/20 Batch 1/3 Cost: 12.608069\n",
      "1\n",
      "[tensor([[73., 80., 75.],\n",
      "        [93., 88., 93.]]), tensor([[152.],\n",
      "        [185.]])]\n",
      "Epoch   13/20 Batch 2/3 Cost: 9.412058\n",
      "2\n",
      "[tensor([[89., 91., 90.]]), tensor([[180.]])]\n",
      "Epoch   13/20 Batch 3/3 Cost: 2.640675\n",
      "0\n",
      "[tensor([[73., 80., 75.],\n",
      "        [93., 88., 93.]]), tensor([[152.],\n",
      "        [185.]])]\n",
      "Epoch   14/20 Batch 1/3 Cost: 10.166107\n",
      "1\n",
      "[tensor([[ 96.,  98., 100.],\n",
      "        [ 73.,  66.,  70.]]), tensor([[196.],\n",
      "        [142.]])]\n",
      "Epoch   14/20 Batch 2/3 Cost: 11.352968\n",
      "2\n",
      "[tensor([[89., 91., 90.]]), tensor([[180.]])]\n",
      "Epoch   14/20 Batch 3/3 Cost: 3.051028\n",
      "0\n",
      "[tensor([[89., 91., 90.],\n",
      "        [93., 88., 93.]]), tensor([[180.],\n",
      "        [185.]])]\n",
      "Epoch   15/20 Batch 1/3 Cost: 7.304117\n",
      "1\n",
      "[tensor([[ 73.,  80.,  75.],\n",
      "        [ 96.,  98., 100.]]), tensor([[152.],\n",
      "        [196.]])]\n",
      "Epoch   15/20 Batch 2/3 Cost: 6.357175\n",
      "2\n",
      "[tensor([[73., 66., 70.]]), tensor([[142.]])]\n",
      "Epoch   15/20 Batch 3/3 Cost: 26.479391\n",
      "0\n",
      "[tensor([[73., 66., 70.],\n",
      "        [73., 80., 75.]]), tensor([[142.],\n",
      "        [152.]])]\n",
      "Epoch   16/20 Batch 1/3 Cost: 13.842113\n",
      "1\n",
      "[tensor([[ 96.,  98., 100.],\n",
      "        [ 93.,  88.,  93.]]), tensor([[196.],\n",
      "        [185.]])]\n",
      "Epoch   16/20 Batch 2/3 Cost: 5.847848\n",
      "2\n",
      "[tensor([[89., 91., 90.]]), tensor([[180.]])]\n",
      "Epoch   16/20 Batch 3/3 Cost: 4.872873\n",
      "0\n",
      "[tensor([[ 96.,  98., 100.],\n",
      "        [ 89.,  91.,  90.]]), tensor([[196.],\n",
      "        [180.]])]\n",
      "Epoch   17/20 Batch 1/3 Cost: 1.447957\n",
      "1\n",
      "[tensor([[73., 66., 70.],\n",
      "        [73., 80., 75.]]), tensor([[142.],\n",
      "        [152.]])]\n",
      "Epoch   17/20 Batch 2/3 Cost: 15.467968\n",
      "2\n",
      "[tensor([[93., 88., 93.]]), tensor([[185.]])]\n",
      "Epoch   17/20 Batch 3/3 Cost: 12.710875\n",
      "0\n",
      "[tensor([[73., 66., 70.],\n",
      "        [73., 80., 75.]]), tensor([[142.],\n",
      "        [152.]])]\n",
      "Epoch   18/20 Batch 1/3 Cost: 14.027610\n",
      "1\n",
      "[tensor([[ 96.,  98., 100.],\n",
      "        [ 93.,  88.,  93.]]), tensor([[196.],\n",
      "        [185.]])]\n",
      "Epoch   18/20 Batch 2/3 Cost: 6.035556\n",
      "2\n",
      "[tensor([[89., 91., 90.]]), tensor([[180.]])]\n",
      "Epoch   18/20 Batch 3/3 Cost: 5.387391\n",
      "0\n",
      "[tensor([[73., 66., 70.],\n",
      "        [89., 91., 90.]]), tensor([[142.],\n",
      "        [180.]])]\n",
      "Epoch   19/20 Batch 1/3 Cost: 11.242458\n",
      "1\n",
      "[tensor([[73., 80., 75.],\n",
      "        [93., 88., 93.]]), tensor([[152.],\n",
      "        [185.]])]\n",
      "Epoch   19/20 Batch 2/3 Cost: 9.186895\n",
      "2\n",
      "[tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n",
      "Epoch   19/20 Batch 3/3 Cost: 3.968629\n",
      "0\n",
      "[tensor([[ 96.,  98., 100.],\n",
      "        [ 73.,  80.,  75.]]), tensor([[196.],\n",
      "        [152.]])]\n",
      "Epoch   20/20 Batch 1/3 Cost: 3.151637\n",
      "1\n",
      "[tensor([[89., 91., 90.],\n",
      "        [73., 66., 70.]]), tensor([[180.],\n",
      "        [142.]])]\n",
      "Epoch   20/20 Batch 2/3 Cost: 15.022988\n",
      "2\n",
      "[tensor([[93., 88., 93.]]), tensor([[185.]])]\n",
      "Epoch   20/20 Batch 3/3 Cost: 12.494633\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        print(batch_idx)\n",
    "        print(samples)\n",
    "        x_train, y_train = samples\n",
    "        # H(x) 계산\n",
    "        prediction = model(x_train)\n",
    "\n",
    "        # cost 계산\n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "        # cost로 H(x) 계산\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch {epoch:4d}/{nb_epochs} Batch {batch_idx+1}/{len(dataloader)} Cost: {cost.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[156.0985]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 임의의 입력 [73, 80, 75]를 선언\n",
    "new_var =  torch.FloatTensor([[73, 80, 75]]) \n",
    "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var) \n",
    "print(pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.utils.data.Dataset을 상속받아 직접 커스텀 데이터셋(Custom Dataset)을 만들 수 있음\n",
    "\n",
    "torch.utils.data.Dataset은 파이토치에서 데이터셋을 제공하는 추상 클래스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 기본적인 define은 3개로 init, len, getitem임\n",
    "\n",
    "init은 생성자로  데이터셋의 전처리를 해주는 부분\n",
    "\n",
    "len은 데이터셋의 길이. 즉, 총 샘플의 수를 적어주는 부분\n",
    "\n",
    "getitem은 데이터셋에서 특정 1개의 샘플을 가져오는 매서드로 인덱싱에 사용되는 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 상속\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_data = [[73, 80, 75],\n",
    "                       [93, 88, 93],\n",
    "                       [89, 91, 90],\n",
    "                       [96, 98, 100],\n",
    "                       [73, 66, 70]]\n",
    "        self.y_data = [[152], [185], [180], [196], [142]]\n",
    "\n",
    "    # 총 데이터의 개수를 리턴\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Linear(3,1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Batch 1/3 Cost: 16755.916016\n",
      "Epoch    0/20 Batch 2/3 Cost: 11733.840820\n",
      "Epoch    0/20 Batch 3/3 Cost: 3416.828369\n",
      "Epoch    1/20 Batch 1/3 Cost: 480.786804\n",
      "Epoch    1/20 Batch 2/3 Cost: 184.408417\n",
      "Epoch    1/20 Batch 3/3 Cost: 55.141773\n",
      "Epoch    2/20 Batch 1/3 Cost: 12.953405\n",
      "Epoch    2/20 Batch 2/3 Cost: 3.665296\n",
      "Epoch    2/20 Batch 3/3 Cost: 7.415599\n",
      "Epoch    3/20 Batch 1/3 Cost: 1.587905\n",
      "Epoch    3/20 Batch 2/3 Cost: 0.689919\n",
      "Epoch    3/20 Batch 3/3 Cost: 0.001479\n",
      "Epoch    4/20 Batch 1/3 Cost: 1.352613\n",
      "Epoch    4/20 Batch 2/3 Cost: 0.089144\n",
      "Epoch    4/20 Batch 3/3 Cost: 1.423597\n",
      "Epoch    5/20 Batch 1/3 Cost: 0.320588\n",
      "Epoch    5/20 Batch 2/3 Cost: 1.540054\n",
      "Epoch    5/20 Batch 3/3 Cost: 1.357885\n",
      "Epoch    6/20 Batch 1/3 Cost: 0.311991\n",
      "Epoch    6/20 Batch 2/3 Cost: 1.576253\n",
      "Epoch    6/20 Batch 3/3 Cost: 1.364614\n",
      "Epoch    7/20 Batch 1/3 Cost: 0.329488\n",
      "Epoch    7/20 Batch 2/3 Cost: 1.819390\n",
      "Epoch    7/20 Batch 3/3 Cost: 0.004660\n",
      "Epoch    8/20 Batch 1/3 Cost: 1.356111\n",
      "Epoch    8/20 Batch 2/3 Cost: 0.064187\n",
      "Epoch    8/20 Batch 3/3 Cost: 1.440322\n",
      "Epoch    9/20 Batch 1/3 Cost: 2.006790\n",
      "Epoch    9/20 Batch 2/3 Cost: 0.128401\n",
      "Epoch    9/20 Batch 3/3 Cost: 0.000005\n",
      "Epoch   10/20 Batch 1/3 Cost: 0.090719\n",
      "Epoch   10/20 Batch 2/3 Cost: 1.715148\n",
      "Epoch   10/20 Batch 3/3 Cost: 0.016636\n",
      "Epoch   11/20 Batch 1/3 Cost: 1.714591\n",
      "Epoch   11/20 Batch 2/3 Cost: 0.060714\n",
      "Epoch   11/20 Batch 3/3 Cost: 0.047060\n",
      "Epoch   12/20 Batch 1/3 Cost: 1.717993\n",
      "Epoch   12/20 Batch 2/3 Cost: 0.061860\n",
      "Epoch   12/20 Batch 3/3 Cost: 0.044798\n",
      "Epoch   13/20 Batch 1/3 Cost: 1.255985\n",
      "Epoch   13/20 Batch 2/3 Cost: 0.939124\n",
      "Epoch   13/20 Batch 3/3 Cost: 0.241603\n",
      "Epoch   14/20 Batch 1/3 Cost: 1.202068\n",
      "Epoch   14/20 Batch 2/3 Cost: 0.878411\n",
      "Epoch   14/20 Batch 3/3 Cost: 0.002774\n",
      "Epoch   15/20 Batch 1/3 Cost: 0.521376\n",
      "Epoch   15/20 Batch 2/3 Cost: 1.532286\n",
      "Epoch   15/20 Batch 3/3 Cost: 0.055858\n",
      "Epoch   16/20 Batch 1/3 Cost: 0.557382\n",
      "Epoch   16/20 Batch 2/3 Cost: 1.772911\n",
      "Epoch   16/20 Batch 3/3 Cost: 0.077700\n",
      "Epoch   17/20 Batch 1/3 Cost: 0.586361\n",
      "Epoch   17/20 Batch 2/3 Cost: 1.607813\n",
      "Epoch   17/20 Batch 3/3 Cost: 0.063565\n",
      "Epoch   18/20 Batch 1/3 Cost: 0.934465\n",
      "Epoch   18/20 Batch 2/3 Cost: 0.439451\n",
      "Epoch   18/20 Batch 3/3 Cost: 1.541969\n",
      "Epoch   19/20 Batch 1/3 Cost: 0.304609\n",
      "Epoch   19/20 Batch 2/3 Cost: 0.293436\n",
      "Epoch   19/20 Batch 3/3 Cost: 3.576079\n",
      "Epoch   20/20 Batch 1/3 Cost: 0.764621\n",
      "Epoch   20/20 Batch 2/3 Cost: 0.577013\n",
      "Epoch   20/20 Batch 3/3 Cost: 1.677060\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        #print(batch_idx)\n",
    "        #print(samples)\n",
    "        x_train, y_train = samples\n",
    "        # H(x) 계산\n",
    "        prediction = model(x_train)\n",
    "\n",
    "        # cost 계산\n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "        # cost로 H(x) 계산\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch {epoch:4d}/{nb_epochs} Batch {batch_idx+1}/{len(dataloader)} Cost: {cost.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[150.0981]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "new_var =  torch.FloatTensor([[73, 80, 75]]) \n",
    "pred_y = model(new_var) \n",
    "print(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
